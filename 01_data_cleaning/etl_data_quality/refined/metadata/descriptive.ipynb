{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81174313-5aa2-444b-854c-678e2c713d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"test_session\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af6ae1c-d70a-4e69-975d-324801a7031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo inicial da execucao: 2025-10-14 21:37:17.637274\n",
      "User: tatiane\n",
      "Node: tatiane-Inspiron-3583\n"
     ]
    }
   ],
   "source": [
    "import sys, os, time, getpass\n",
    "\n",
    "sys.path.append(\"/home/tatiane/lib/\")\n",
    "\n",
    "import pessoal\n",
    "from pessoal import *\n",
    "#print('AppID: ', sc.applicationId)\n",
    "\n",
    "# Pedir ao spark para exibir só erros, escondendo avisos (WARN) e infos\n",
    "# O correto é resolver a causa como, por exemplo: ordenados = Window.partitionBy().orderBy(dfs[i].columns[0])\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc59b0e-36a6-498a-884a-c46a9f9cf30f",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937f5058-db11-470d-a228-ee29f3cb5457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd. registros: 100 | Quantidade de colunas:  5\n",
      "root\n",
      " |-- municipio_nascimento: string (nullable = true)\n",
      " |-- sexo: string (nullable = true)\n",
      " |-- id_unico: integer (nullable = true)\n",
      " |-- data_nascimento: string (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "padronizado_path = '/home/tatiane/Documentos/tratamento_dados/processing/data/processing.csv'\n",
    "padronizado = spark.read.csv(padronizado_path, header=True, inferSchema=True)\n",
    "pessoal.completudeSchema(padronizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c585776-3275-4333-ba05-961c645e5f3e",
   "metadata": {},
   "source": [
    "## Validação de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96a9e5b-7293-4729-87d6-36e57d006ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_colunas(df):\n",
    "    \"\"\"\n",
    "    Retorna um DataFrame com métricas de validação para cada coluna:\n",
    "    - tipo da variável\n",
    "    - nulos\n",
    "    - preenchidos\n",
    "    - únicos\n",
    "    - duplicados\n",
    "    - valor mínimo (para numéricos e datas)\n",
    "    - valor máximo (para numéricos e datas)\n",
    "    - média (para numéricos)\n",
    "    \"\"\"\n",
    "    total = df.count()\n",
    "    resultado = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        nulos = df.filter(F.col(col).isNull()).count()\n",
    "        preenchidos = total - nulos\n",
    "        unicos = df.select(col).distinct().count()\n",
    "        duplicados = total - unicos\n",
    "\n",
    "        # Inicializa métricas opcionais\n",
    "        minimo, maximo, media = (None, None, None)\n",
    "\n",
    "        # Verifica se a coluna é numérica\n",
    "        if df.schema[col].dataType.simpleString() in [\"int\", \"bigint\", \"double\", \"float\", \"decimal\"]:\n",
    "            stats = df.select(\n",
    "                F.min(F.col(col)).alias(\"minimo\"),\n",
    "                F.max(F.col(col)).alias(\"maximo\"),\n",
    "                F.mean(F.col(col)).alias(\"media\")\n",
    "            ).collect()[0]\n",
    "            minimo, maximo, media = stats[\"minimo\"], stats[\"maximo\"], stats[\"media\"]\n",
    "\n",
    "        # Verifica se é uma coluna de data\n",
    "        elif \"date\" in df.schema[col].dataType.simpleString():\n",
    "            stats = df.select(\n",
    "                F.min(F.col(col)).alias(\"minimo\"),\n",
    "                F.max(F.col(col)).alias(\"maximo\")\n",
    "            ).collect()[0]\n",
    "            minimo, maximo = stats[\"minimo\"], stats[\"maximo\"]\n",
    "\n",
    "        resultado.append((col, nulos, preenchidos, unicos, duplicados, minimo, maximo, media))\n",
    "    \n",
    "    # Criar DataFrame PySpark com resultados\n",
    "    schema = [\"coluna\", \"nulos\", \"preenchidos\", \"unicos\", \"duplicados\", \"minimo\", \"maximo\", \"media\"]\n",
    "    return spark.createDataFrame(resultado, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4019775-e326-4e4c-b29b-c1f8ae88809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_outliers(df):\n",
    "    \"\"\"\n",
    "    Retorna um DataFrame com contagem de outliers para cada variável numérica.\n",
    "    Método: IQR (Interquartile Range)\n",
    "    \"\"\"\n",
    "    resultado = []\n",
    "    num_cols = [f.name for f in df.schema.fields if f.dataType.simpleString() in ['int', 'double', 'float', 'bigint']]\n",
    "\n",
    "    for col in num_cols:\n",
    "        q1, q3 = df.approxQuantile(col, [0.25, 0.75], 0.05)\n",
    "        iqr = q3 - q1\n",
    "        limite_inf = q1 - 1.5 * iqr\n",
    "        limite_sup = q3 + 1.5 * iqr\n",
    "\n",
    "        total = df.count()\n",
    "        outliers = df.filter((F.col(col) < limite_inf) | (F.col(col) > limite_sup)).count()\n",
    "        perc_outliers = round((outliers / total) * 100, 2)\n",
    "\n",
    "        resultado.append((col, total, outliers, perc_outliers, limite_inf, limite_sup))\n",
    "\n",
    "    schema = [\"coluna\", \"total_registros\", \"qtd_outliers\", \"perc_outliers\", \"limite_inferior\", \"limite_superior\"]\n",
    "    return df.sparkSession.createDataFrame(resultado, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa254d45-c371-4dc6-8067-3817d8cc0eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coluna</th>\n",
       "      <th>nulos</th>\n",
       "      <th>preenchidos</th>\n",
       "      <th>unicos</th>\n",
       "      <th>duplicados</th>\n",
       "      <th>minimo</th>\n",
       "      <th>maximo</th>\n",
       "      <th>media</th>\n",
       "      <th>total_registros</th>\n",
       "      <th>qtd_outliers</th>\n",
       "      <th>perc_outliers</th>\n",
       "      <th>limite_inferior</th>\n",
       "      <th>limite_superior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>municipio_nascimento</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexo</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_unico</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-56.5</td>\n",
       "      <td>147.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_nascimento</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nome</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coluna  nulos  preenchidos  unicos  duplicados  minimo  \\\n",
       "0  municipio_nascimento      0          100      10          90     NaN   \n",
       "1                  sexo      0          100       2          98     NaN   \n",
       "2              id_unico      0          100     100           0     1.0   \n",
       "3       data_nascimento      0          100     100           0     NaN   \n",
       "4                  nome      0          100      20          80     NaN   \n",
       "\n",
       "   maximo  media  total_registros  qtd_outliers  perc_outliers  \\\n",
       "0     NaN    NaN              NaN           NaN            NaN   \n",
       "1     NaN    NaN              NaN           NaN            NaN   \n",
       "2   100.0   50.5            100.0           0.0            0.0   \n",
       "3     NaN    NaN              NaN           NaN            NaN   \n",
       "4     NaN    NaN              NaN           NaN            NaN   \n",
       "\n",
       "   limite_inferior  limite_superior  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2            -56.5            147.5  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = validar_colunas(padronizado)\n",
    "df_out = detectar_outliers(padronizado)\n",
    "\n",
    "df_final = df_valid.join(df_out, on=\"coluna\", how=\"left\")\n",
    "df_final.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e0bff-dbb4-4913-b273-79a068d329ca",
   "metadata": {},
   "source": [
    "### Distribuição das varáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c60f8f4-e4e9-474e-9619-a5581b74bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "padronizado = padronizado.withColumn(\"sexo\", F.col(\"sexo\").cast(ByteType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ba5eed5-0ca0-49d7-90bf-b77ae0430a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_ls = [x[0] for x in padronizado.dtypes if x[1] == 'tinyint']\n",
    "dates_ls = [x[0] for x in padronizado.dtypes if x[1] == 'date']\n",
    "string_ls = [x[0] for x in padronizado.dtypes if x[1] == 'string']\n",
    "integer_ls = [x[0] for x in padronizado.dtypes if x[1] == 'int']\n",
    "long_ls = [x[0] for x in padronizado.dtypes if x[1] == 'bigint']\n",
    "double_ls = [x[0] for x in padronizado.dtypes if x[1] == 'double']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e79d282-c038-4b57-9169-cae942891f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = byte_ls[:]\n",
    "count_base = padronizado.count()\n",
    "for i, var in enumerate(l):\n",
    "    print(f'{i + 1}/{len(l)}')\n",
    "    print(f'Distribuição geral da variável `{var}`:')\n",
    "    padronizado.groupBy(var).count().orderBy(F.col(var)).withColumn('%', F.round(F.col('count')/count_base * 100, 2)).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6a9985-fdd2-4ba4-9775-6a89290437b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição geral da variável sexo:\n",
      "+----+-----+----+\n",
      "|sexo|count|   %|\n",
      "+----+-----+----+\n",
      "|   F|   50|50.0|\n",
      "|   M|   50|50.0|\n",
      "+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_base = padronizado.count()\n",
    "print(f'Distribuição geral da variável sexo:')\n",
    "padronizado.groupBy('sexo').count().orderBy(F.col('sexo')).withColumn('%', F.round(F.col('count')/count_base * 100, 2)).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a9d9474-accc-4f04-996f-737a7b41141d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook descriptive.ipynb to html\n",
      "[NbConvertApp] Writing 277441 bytes to descriptive.html\n"
     ]
    }
   ],
   "source": [
    "#download HTML\n",
    "!jupyter nbconvert --to html --no-input descriptive.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Spark Venv)",
   "language": "python",
   "name": "meu_ambiente"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
